{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8b1de9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image as mp_image\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e43d21da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# seed\n",
    "np.random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# GPU seed\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7e25e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epoch = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f3c4264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file_list(path):\n",
    "    train_img_list = list()\n",
    "\n",
    "    with os.scandir(path) as files:\n",
    "        for file in files:\n",
    "            if file.name.endswith('.jpg'):\n",
    "              # adds only the image files to the flowers list\n",
    "                train_img_list.append(f\"{path}/{file.name}\")\n",
    "    \n",
    "    return train_img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4939b769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./archive/train/hot_dog/3622018.jpg'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make train dataloader list\n",
    "\n",
    "hot_dogs_path = r\"./archive/train/hot_dog\"\n",
    "not_hot_dogs_path = r\"./archive/train/not_hot_dog\"\n",
    "\n",
    "hot_dogs_train = make_file_list(hot_dogs_path)\n",
    "not_hot_dogs_train = make_file_list(not_hot_dogs_path)\n",
    "\n",
    "hot_dogs_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e0295390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transform \n",
    "class ImageTransform():\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d641bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Custom Dataset\n",
    "class ImageDataset(Data.Dataset):\n",
    "    def __init__(self, file_list, transform):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        return img_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "069a34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "#     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "training_path = r\"./archive/train\"\n",
    "test_path = r\"./archive/test\"\n",
    "train_data = datasets.ImageFolder(root=training_path, transform=trans)\n",
    "test_data = datasets.ImageFolder(root=test_path, transform=trans)\n",
    "\n",
    "\n",
    "train_set = torch.utils.data.DataLoader(dataset=train_data, batch_size=30, shuffle=True)\n",
    "test_set = torch.utils.data.DataLoader(dataset=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "60ceacc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = nn.Flatten()(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "425501cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural net class\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    \n",
    "    # Defining the Constructor\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # In the init function, we define each layer we will use in our model\n",
    "        \n",
    "        # Our images are RGB, so we have input channels = 3. \n",
    "        # We will apply 12 filters in the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # A second convolutional layer takes 12 input channels, and generates 24 outputs\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # We in the end apply max pooling with a kernel size of 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # A drop layer deletes 20% of the features to help prevent overfitting\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        # Our 128x128 image tensors will be pooled twice with a kernel size of 2. 128/2/2 is 32.\n",
    "        # This means that our feature tensors are now 32 x 32, and we've generated 24 of them\n",
    "        \n",
    "        # We need to flatten these in order to feed them to a fully-connected layer\n",
    "        self.fc = nn.Linear(in_features=64 * 64 * 24, out_features=8*8*24)\n",
    "        self.fc2 = nn.Linear(in_features=8*8*24, out_features=num_classes, bais=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # In the forward function, pass the data through the layers we defined in the init function\n",
    "        \n",
    "        # Use a ReLU activation function after layer 1 (convolution 1 and pool)\n",
    "        x = F.relu(self.pool(self.conv1(x))) \n",
    "        \n",
    "        # Use a ReLU activation function after layer 2\n",
    "        x = F.relu(self.pool(self.conv2(x)))  \n",
    "        \n",
    "        # Select some features to drop to prevent overfitting (only drop during training)\n",
    "        x = F.dropout(self.drop(x), training=self.training)\n",
    "        \n",
    "        # Flatten\n",
    "        x  = nn.Flatten()(x)\n",
    "        \n",
    "        # Feed to fully-connected layer to predict class\n",
    "        x = self.fc(x)\n",
    "        x = self.fc2(x)\n",
    "        # Return class probabilities via a log_softmax function \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "764f22c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'bais'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-ea62abdf8deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-188-582da9f030c9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# We need to flatten these in order to feed them to a fully-connected layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbais\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'bais'"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d266f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Use the CPU or GPU as appropriate\n",
    "        # Recall that GPU is optimized for the operations we are dealing with\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_criteria(output, target)\n",
    "\n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predicted = torch.argmax(output, 1) == target\n",
    "        running_correct = predicted.float().mean()\n",
    "        \n",
    "        # Print metrics so we see some progress\n",
    "        print('\\tTraining batch {} Loss: {:.6f} cost = {:.4f}'.format(batch_idx + 1, loss.item(),running_correct*100))\n",
    "            \n",
    "    # return average loss for the epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    print('Training set: Average loss: {:.6f} '.format(avg_loss))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "24463058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        batch_count = 0\n",
    "        for data, target in test_loader:\n",
    "            batch_count += 1\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += loss_criteria(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += torch.sum(target==predicted).item()\n",
    "\n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    avg_loss = test_loss / batch_count\n",
    "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41902f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Epoch: 1\n",
      "\tTraining batch 1 Loss: 0.095566 cost = 100.0000\n",
      "\tTraining batch 2 Loss: 0.561506 cost = 70.0000\n",
      "\tTraining batch 3 Loss: 0.073822 cost = 96.6667\n",
      "\tTraining batch 4 Loss: 0.436284 cost = 76.6667\n",
      "\tTraining batch 5 Loss: 0.262155 cost = 90.0000\n",
      "\tTraining batch 6 Loss: 0.097429 cost = 96.6667\n",
      "\tTraining batch 7 Loss: 0.201020 cost = 93.3333\n",
      "\tTraining batch 8 Loss: 0.417563 cost = 76.6667\n",
      "\tTraining batch 9 Loss: 0.361313 cost = 90.0000\n",
      "\tTraining batch 10 Loss: 0.081345 cost = 100.0000\n",
      "\tTraining batch 11 Loss: 0.191327 cost = 93.3333\n",
      "\tTraining batch 12 Loss: 0.143621 cost = 96.6667\n",
      "\tTraining batch 13 Loss: 0.199051 cost = 93.3333\n",
      "\tTraining batch 14 Loss: 0.135661 cost = 96.6667\n",
      "\tTraining batch 15 Loss: 0.139023 cost = 90.0000\n",
      "\tTraining batch 16 Loss: 0.118279 cost = 93.3333\n",
      "\tTraining batch 17 Loss: 0.168247 cost = 94.4444\n",
      "Training set: Average loss: 0.216659 \n",
      "Validation set: Average loss: 1.014064, Accuracy: 288/500 (58%)\n",
      "\n",
      "Epoch: 2\n",
      "\tTraining batch 1 Loss: 0.166987 cost = 96.6667\n",
      "\tTraining batch 2 Loss: 0.197499 cost = 90.0000\n",
      "\tTraining batch 3 Loss: 0.175653 cost = 90.0000\n",
      "\tTraining batch 4 Loss: 0.181759 cost = 90.0000\n",
      "\tTraining batch 5 Loss: 0.053652 cost = 100.0000\n",
      "\tTraining batch 6 Loss: 0.113951 cost = 96.6667\n",
      "\tTraining batch 7 Loss: 0.150272 cost = 96.6667\n",
      "\tTraining batch 8 Loss: 0.174873 cost = 93.3333\n",
      "\tTraining batch 9 Loss: 0.084824 cost = 100.0000\n",
      "\tTraining batch 10 Loss: 0.116236 cost = 96.6667\n",
      "\tTraining batch 11 Loss: 0.122050 cost = 100.0000\n",
      "\tTraining batch 12 Loss: 0.144348 cost = 100.0000\n",
      "\tTraining batch 13 Loss: 0.090096 cost = 96.6667\n",
      "\tTraining batch 14 Loss: 0.077634 cost = 100.0000\n",
      "\tTraining batch 15 Loss: 0.081931 cost = 100.0000\n",
      "\tTraining batch 16 Loss: 0.070356 cost = 100.0000\n",
      "\tTraining batch 17 Loss: 0.147775 cost = 88.8889\n",
      "Training set: Average loss: 0.126465 \n",
      "Validation set: Average loss: 0.949562, Accuracy: 299/500 (60%)\n",
      "\n",
      "Epoch: 3\n",
      "\tTraining batch 1 Loss: 0.192316 cost = 93.3333\n",
      "\tTraining batch 2 Loss: 0.021158 cost = 100.0000\n"
     ]
    }
   ],
   "source": [
    "# Use an \"Adam\" optimizer to adjust weights\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Specify the loss criteria\n",
    "loss_criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Track metrics in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "\n",
    "\n",
    "# Train over 10 epochs (We restrict to 10 for time issues)\n",
    "epochs = 10\n",
    "print('Training on', device)\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, device, train_set, optimizer, epoch)\n",
    "        test_loss = test(model, device, test_set)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "be3d44f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set: Average loss: 0.925093, Accuracy: 286/500 (57%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation_loss = []\n",
    "\n",
    "\n",
    "test_loss = test(model, device, test_set)\n",
    "validation_loss.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "564cf09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([12, 3, 3, 3])\n",
      "conv1.bias \t torch.Size([12])\n",
      "conv2.weight \t torch.Size([24, 12, 3, 3])\n",
      "conv2.bias \t torch.Size([24])\n",
      "fc.weight \t torch.Size([2, 98304])\n",
      "fc.bias \t torch.Size([2])\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': 170, 'exp_avg': tensor([[[[ 0.0158,  0.0135,  0.0103],\n",
      "          [ 0.0145,  0.0129,  0.0094],\n",
      "          [ 0.0111,  0.0084,  0.0063]],\n",
      "\n",
      "         [[ 0.0338,  0.0305,  0.0265],\n",
      "          [ 0.0327,  0.0304,  0.0257],\n",
      "          [ 0.0286,  0.0253,  0.0222]],\n",
      "\n",
      "         [[ 0.0368,  0.0324,  0.0274],\n",
      "          [ 0.0359,  0.0325,  0.0273],\n",
      "          [ 0.0316,  0.0274,  0.0241]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0079,  0.0087,  0.0100],\n",
      "          [ 0.0060,  0.0074,  0.0082],\n",
      "          [ 0.0004,  0.0026,  0.0033]],\n",
      "\n",
      "         [[ 0.0137,  0.0141,  0.0146],\n",
      "          [ 0.0106,  0.0116,  0.0117],\n",
      "          [ 0.0032,  0.0049,  0.0050]],\n",
      "\n",
      "         [[ 0.0124,  0.0118,  0.0116],\n",
      "          [ 0.0094,  0.0097,  0.0094],\n",
      "          [ 0.0021,  0.0033,  0.0031]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0070,  0.0023, -0.0004],\n",
      "          [ 0.0102,  0.0058,  0.0011],\n",
      "          [ 0.0087,  0.0049,  0.0011]],\n",
      "\n",
      "         [[ 0.0030, -0.0017, -0.0045],\n",
      "          [ 0.0063,  0.0019, -0.0029],\n",
      "          [ 0.0049,  0.0013, -0.0026]],\n",
      "\n",
      "         [[ 0.0086,  0.0027, -0.0005],\n",
      "          [ 0.0110,  0.0054,  0.0002],\n",
      "          [ 0.0096,  0.0046,  0.0004]]],\n",
      "\n",
      "\n",
      "        [[[-0.0169, -0.0158, -0.0134],\n",
      "          [-0.0136, -0.0145, -0.0126],\n",
      "          [-0.0100, -0.0119, -0.0116]],\n",
      "\n",
      "         [[-0.0002,  0.0019,  0.0062],\n",
      "          [ 0.0047,  0.0049,  0.0081],\n",
      "          [ 0.0096,  0.0084,  0.0099]],\n",
      "\n",
      "         [[ 0.0038,  0.0057,  0.0104],\n",
      "          [ 0.0090,  0.0086,  0.0122],\n",
      "          [ 0.0141,  0.0126,  0.0143]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0202,  0.0187,  0.0184],\n",
      "          [ 0.0250,  0.0229,  0.0217],\n",
      "          [ 0.0260,  0.0248,  0.0238]],\n",
      "\n",
      "         [[ 0.0091,  0.0089,  0.0097],\n",
      "          [ 0.0129,  0.0123,  0.0122],\n",
      "          [ 0.0127,  0.0130,  0.0131]],\n",
      "\n",
      "         [[ 0.0255,  0.0250,  0.0253],\n",
      "          [ 0.0295,  0.0287,  0.0281],\n",
      "          [ 0.0287,  0.0288,  0.0288]]],\n",
      "\n",
      "\n",
      "        [[[-0.0117, -0.0097, -0.0041],\n",
      "          [-0.0076, -0.0062, -0.0028],\n",
      "          [ 0.0006,  0.0020,  0.0015]],\n",
      "\n",
      "         [[-0.0192, -0.0155, -0.0088],\n",
      "          [-0.0141, -0.0111, -0.0067],\n",
      "          [-0.0052, -0.0024, -0.0020]],\n",
      "\n",
      "         [[-0.0104, -0.0062,  0.0009],\n",
      "          [-0.0051, -0.0018,  0.0030],\n",
      "          [ 0.0036,  0.0066,  0.0072]]],\n",
      "\n",
      "\n",
      "        [[[-0.0172, -0.0179, -0.0179],\n",
      "          [-0.0157, -0.0159, -0.0166],\n",
      "          [-0.0148, -0.0151, -0.0154]],\n",
      "\n",
      "         [[-0.0173, -0.0179, -0.0182],\n",
      "          [-0.0156, -0.0156, -0.0163],\n",
      "          [-0.0146, -0.0148, -0.0152]],\n",
      "\n",
      "         [[-0.0081, -0.0091, -0.0100],\n",
      "          [-0.0066, -0.0070, -0.0081],\n",
      "          [-0.0058, -0.0062, -0.0070]]],\n",
      "\n",
      "\n",
      "        [[[-0.0041, -0.0031, -0.0031],\n",
      "          [-0.0039, -0.0022, -0.0025],\n",
      "          [-0.0083, -0.0068, -0.0068]],\n",
      "\n",
      "         [[-0.0065, -0.0054, -0.0049],\n",
      "          [-0.0067, -0.0047, -0.0045],\n",
      "          [-0.0111, -0.0094, -0.0088]],\n",
      "\n",
      "         [[ 0.0037,  0.0053,  0.0057],\n",
      "          [ 0.0037,  0.0062,  0.0062],\n",
      "          [-0.0004,  0.0015,  0.0016]]],\n",
      "\n",
      "\n",
      "        [[[-0.0065, -0.0115, -0.0141],\n",
      "          [-0.0021, -0.0077, -0.0105],\n",
      "          [ 0.0012, -0.0027, -0.0060]],\n",
      "\n",
      "         [[-0.0037, -0.0093, -0.0121],\n",
      "          [ 0.0015, -0.0049, -0.0081],\n",
      "          [ 0.0060,  0.0012, -0.0027]],\n",
      "\n",
      "         [[-0.0082, -0.0149, -0.0180],\n",
      "          [-0.0023, -0.0097, -0.0135],\n",
      "          [ 0.0026, -0.0031, -0.0073]]],\n",
      "\n",
      "\n",
      "        [[[-0.0169, -0.0179, -0.0181],\n",
      "          [-0.0181, -0.0189, -0.0196],\n",
      "          [-0.0179, -0.0185, -0.0194]],\n",
      "\n",
      "         [[-0.0196, -0.0212, -0.0212],\n",
      "          [-0.0211, -0.0226, -0.0233],\n",
      "          [-0.0211, -0.0226, -0.0234]],\n",
      "\n",
      "         [[-0.0281, -0.0303, -0.0301],\n",
      "          [-0.0296, -0.0321, -0.0327],\n",
      "          [-0.0295, -0.0319, -0.0324]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0044,  0.0029,  0.0040],\n",
      "          [ 0.0098,  0.0071,  0.0062],\n",
      "          [ 0.0143,  0.0119,  0.0082]],\n",
      "\n",
      "         [[ 0.0099,  0.0091,  0.0105],\n",
      "          [ 0.0160,  0.0139,  0.0130],\n",
      "          [ 0.0216,  0.0198,  0.0158]],\n",
      "\n",
      "         [[ 0.0125,  0.0114,  0.0124],\n",
      "          [ 0.0179,  0.0157,  0.0146],\n",
      "          [ 0.0226,  0.0207,  0.0169]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0017,  0.0027,  0.0042],\n",
      "          [-0.0008,  0.0001,  0.0012],\n",
      "          [-0.0020, -0.0021, -0.0020]],\n",
      "\n",
      "         [[ 0.0077,  0.0095,  0.0109],\n",
      "          [ 0.0064,  0.0077,  0.0087],\n",
      "          [ 0.0059,  0.0060,  0.0058]],\n",
      "\n",
      "         [[ 0.0083,  0.0104,  0.0123],\n",
      "          [ 0.0072,  0.0091,  0.0105],\n",
      "          [ 0.0075,  0.0081,  0.0080]]]]), 'exp_avg_sq': tensor([[[[0.0062, 0.0067, 0.0067],\n",
      "          [0.0063, 0.0071, 0.0076],\n",
      "          [0.0066, 0.0083, 0.0090]],\n",
      "\n",
      "         [[0.0021, 0.0024, 0.0025],\n",
      "          [0.0022, 0.0026, 0.0030],\n",
      "          [0.0024, 0.0033, 0.0037]],\n",
      "\n",
      "         [[0.0021, 0.0020, 0.0021],\n",
      "          [0.0021, 0.0021, 0.0020],\n",
      "          [0.0021, 0.0019, 0.0020]]],\n",
      "\n",
      "\n",
      "        [[[0.0023, 0.0027, 0.0028],\n",
      "          [0.0024, 0.0029, 0.0028],\n",
      "          [0.0021, 0.0025, 0.0023]],\n",
      "\n",
      "         [[0.0040, 0.0045, 0.0046],\n",
      "          [0.0041, 0.0047, 0.0046],\n",
      "          [0.0036, 0.0041, 0.0038]],\n",
      "\n",
      "         [[0.0037, 0.0041, 0.0041],\n",
      "          [0.0038, 0.0043, 0.0041],\n",
      "          [0.0033, 0.0037, 0.0035]]],\n",
      "\n",
      "\n",
      "        [[[0.0011, 0.0009, 0.0007],\n",
      "          [0.0012, 0.0010, 0.0007],\n",
      "          [0.0012, 0.0010, 0.0008]],\n",
      "\n",
      "         [[0.0012, 0.0010, 0.0008],\n",
      "          [0.0014, 0.0011, 0.0008],\n",
      "          [0.0014, 0.0012, 0.0009]],\n",
      "\n",
      "         [[0.0011, 0.0010, 0.0008],\n",
      "          [0.0013, 0.0011, 0.0008],\n",
      "          [0.0013, 0.0011, 0.0009]]],\n",
      "\n",
      "\n",
      "        [[[0.0009, 0.0009, 0.0008],\n",
      "          [0.0009, 0.0009, 0.0007],\n",
      "          [0.0009, 0.0008, 0.0008]],\n",
      "\n",
      "         [[0.0007, 0.0006, 0.0005],\n",
      "          [0.0007, 0.0006, 0.0006],\n",
      "          [0.0006, 0.0006, 0.0006]],\n",
      "\n",
      "         [[0.0006, 0.0006, 0.0005],\n",
      "          [0.0006, 0.0006, 0.0006],\n",
      "          [0.0006, 0.0006, 0.0006]]],\n",
      "\n",
      "\n",
      "        [[[0.0073, 0.0078, 0.0074],\n",
      "          [0.0061, 0.0069, 0.0069],\n",
      "          [0.0053, 0.0058, 0.0060]],\n",
      "\n",
      "         [[0.0047, 0.0052, 0.0049],\n",
      "          [0.0038, 0.0044, 0.0045],\n",
      "          [0.0032, 0.0036, 0.0038]],\n",
      "\n",
      "         [[0.0025, 0.0027, 0.0027],\n",
      "          [0.0023, 0.0025, 0.0025],\n",
      "          [0.0022, 0.0023, 0.0023]]],\n",
      "\n",
      "\n",
      "        [[[0.0016, 0.0015, 0.0013],\n",
      "          [0.0014, 0.0014, 0.0013],\n",
      "          [0.0012, 0.0012, 0.0012]],\n",
      "\n",
      "         [[0.0008, 0.0007, 0.0007],\n",
      "          [0.0007, 0.0007, 0.0007],\n",
      "          [0.0007, 0.0007, 0.0007]],\n",
      "\n",
      "         [[0.0008, 0.0009, 0.0010],\n",
      "          [0.0009, 0.0010, 0.0011],\n",
      "          [0.0012, 0.0012, 0.0012]]],\n",
      "\n",
      "\n",
      "        [[[0.0015, 0.0016, 0.0015],\n",
      "          [0.0012, 0.0012, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0010]],\n",
      "\n",
      "         [[0.0009, 0.0010, 0.0009],\n",
      "          [0.0007, 0.0008, 0.0008],\n",
      "          [0.0007, 0.0007, 0.0007]],\n",
      "\n",
      "         [[0.0007, 0.0008, 0.0007],\n",
      "          [0.0008, 0.0008, 0.0007],\n",
      "          [0.0008, 0.0008, 0.0008]]],\n",
      "\n",
      "\n",
      "        [[[0.0007, 0.0006, 0.0007],\n",
      "          [0.0007, 0.0007, 0.0007],\n",
      "          [0.0008, 0.0008, 0.0008]],\n",
      "\n",
      "         [[0.0009, 0.0010, 0.0010],\n",
      "          [0.0010, 0.0010, 0.0010],\n",
      "          [0.0011, 0.0011, 0.0011]],\n",
      "\n",
      "         [[0.0019, 0.0020, 0.0020],\n",
      "          [0.0020, 0.0020, 0.0019],\n",
      "          [0.0020, 0.0020, 0.0019]]],\n",
      "\n",
      "\n",
      "        [[[0.0064, 0.0079, 0.0082],\n",
      "          [0.0058, 0.0070, 0.0072],\n",
      "          [0.0050, 0.0059, 0.0062]],\n",
      "\n",
      "         [[0.0049, 0.0065, 0.0070],\n",
      "          [0.0043, 0.0056, 0.0059],\n",
      "          [0.0035, 0.0044, 0.0048]],\n",
      "\n",
      "         [[0.0042, 0.0059, 0.0064],\n",
      "          [0.0036, 0.0050, 0.0054],\n",
      "          [0.0028, 0.0037, 0.0041]]],\n",
      "\n",
      "\n",
      "        [[[0.0076, 0.0078, 0.0078],\n",
      "          [0.0080, 0.0081, 0.0080],\n",
      "          [0.0078, 0.0082, 0.0079]],\n",
      "\n",
      "         [[0.0068, 0.0070, 0.0071],\n",
      "          [0.0073, 0.0075, 0.0074],\n",
      "          [0.0071, 0.0076, 0.0074]],\n",
      "\n",
      "         [[0.0051, 0.0054, 0.0055],\n",
      "          [0.0056, 0.0059, 0.0059],\n",
      "          [0.0056, 0.0061, 0.0059]]],\n",
      "\n",
      "\n",
      "        [[[0.0036, 0.0036, 0.0036],\n",
      "          [0.0034, 0.0036, 0.0036],\n",
      "          [0.0032, 0.0033, 0.0035]],\n",
      "\n",
      "         [[0.0027, 0.0027, 0.0028],\n",
      "          [0.0026, 0.0027, 0.0028],\n",
      "          [0.0025, 0.0026, 0.0027]],\n",
      "\n",
      "         [[0.0020, 0.0021, 0.0022],\n",
      "          [0.0020, 0.0021, 0.0022],\n",
      "          [0.0020, 0.0020, 0.0021]]],\n",
      "\n",
      "\n",
      "        [[[0.0087, 0.0074, 0.0069],\n",
      "          [0.0082, 0.0075, 0.0076],\n",
      "          [0.0074, 0.0077, 0.0081]],\n",
      "\n",
      "         [[0.0025, 0.0020, 0.0018],\n",
      "          [0.0023, 0.0020, 0.0020],\n",
      "          [0.0019, 0.0020, 0.0022]],\n",
      "\n",
      "         [[0.0011, 0.0011, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0011],\n",
      "          [0.0011, 0.0011, 0.0010]]]])}, 1: {'step': 170, 'exp_avg': tensor([-0.0056, -0.0045, -0.0071, -0.0120,  0.0008,  0.0055,  0.0125,  0.0013,\n",
      "        -0.0017, -0.0167,  0.0049, -0.0091]), 'exp_avg_sq': tensor([0.0141, 0.0027, 0.0010, 0.0008, 0.0105, 0.0020, 0.0028, 0.0043, 0.0071,\n",
      "        0.0063, 0.0018, 0.0088])}, 2: {'step': 170, 'exp_avg': tensor([[[[ 6.5418e-04, -1.4759e-03, -7.2543e-04],\n",
      "          [ 2.0428e-04, -1.5178e-03, -7.8082e-04],\n",
      "          [-3.1644e-04, -1.7665e-03, -8.7568e-04]],\n",
      "\n",
      "         [[-5.0514e-04, -1.8762e-05,  4.2440e-05],\n",
      "          [-1.0379e-03, -3.7840e-05,  6.1860e-05],\n",
      "          [-3.8920e-04,  2.4721e-04,  4.4113e-04]],\n",
      "\n",
      "         [[-1.4465e-03, -2.7359e-03, -2.2696e-04],\n",
      "          [-8.5979e-04, -2.6339e-03, -9.5282e-04],\n",
      "          [-2.7330e-04, -1.5804e-03, -5.7363e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8877e-03,  2.5765e-03,  1.7803e-03],\n",
      "          [ 5.0586e-03,  3.0205e-03,  1.8500e-03],\n",
      "          [ 4.1031e-03,  2.4403e-03,  1.8325e-03]],\n",
      "\n",
      "         [[ 2.8859e-04, -4.1022e-04,  2.3692e-04],\n",
      "          [ 8.6324e-04,  1.9804e-05,  7.2289e-05],\n",
      "          [ 9.6162e-04,  3.1054e-04,  5.4776e-04]],\n",
      "\n",
      "         [[-6.2793e-04, -5.2532e-04, -4.0748e-04],\n",
      "          [-7.3067e-04, -4.4852e-04, -4.6878e-04],\n",
      "          [-6.9551e-04, -4.8304e-04, -4.5873e-04]]],\n",
      "\n",
      "\n",
      "        [[[-6.7312e-03, -1.0257e-02, -1.1565e-02],\n",
      "          [-6.2521e-03, -1.2067e-02, -1.5486e-02],\n",
      "          [-6.9533e-03, -1.1067e-02, -1.7179e-02]],\n",
      "\n",
      "         [[ 2.2151e-02,  1.7635e-02,  4.5964e-03],\n",
      "          [ 1.0719e-02,  9.6113e-03,  5.6711e-03],\n",
      "          [-3.6393e-03, -6.0063e-03, -1.5578e-03]],\n",
      "\n",
      "         [[ 3.7504e-03,  3.6907e-03,  4.9784e-03],\n",
      "          [-1.3114e-03, -1.6371e-03,  2.3471e-03],\n",
      "          [-5.1426e-04, -3.2274e-03, -1.5364e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9565e-04,  3.1602e-03,  6.0778e-03],\n",
      "          [ 5.2819e-03,  7.3470e-03,  7.4765e-03],\n",
      "          [ 8.2741e-03,  1.0128e-02,  7.2027e-03]],\n",
      "\n",
      "         [[ 9.6986e-04, -1.6721e-03, -2.4304e-04],\n",
      "          [-4.7230e-03, -7.4447e-03, -7.1010e-03],\n",
      "          [-1.1950e-03, -6.5317e-03, -8.0569e-03]],\n",
      "\n",
      "         [[-6.8160e-03, -1.1257e-02, -1.3660e-02],\n",
      "          [-9.1923e-03, -1.4769e-02, -1.5855e-02],\n",
      "          [-1.0793e-02, -1.3729e-02, -1.4633e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3416e-03, -2.3879e-03, -2.1356e-03],\n",
      "          [-2.5989e-03, -1.6647e-03, -1.4397e-03],\n",
      "          [-2.0686e-03, -1.4573e-03, -1.7300e-03]],\n",
      "\n",
      "         [[-3.8807e-03, -2.8999e-03, -4.1616e-03],\n",
      "          [-2.9464e-04,  2.7023e-03,  1.5686e-03],\n",
      "          [-3.3731e-04,  3.2231e-03,  3.3032e-03]],\n",
      "\n",
      "         [[-2.4774e-04,  1.0850e-03,  7.0508e-04],\n",
      "          [-7.6670e-04,  9.4095e-04,  1.3317e-03],\n",
      "          [-3.4820e-04,  8.8054e-04,  1.3894e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2704e-02, -1.1996e-02, -1.0425e-02],\n",
      "          [-1.3998e-02, -1.4037e-02, -1.2750e-02],\n",
      "          [-1.2989e-02, -1.2973e-02, -1.2444e-02]],\n",
      "\n",
      "         [[-1.4070e-03, -4.6959e-04, -1.8529e-04],\n",
      "          [-1.9700e-03, -1.6095e-03, -1.1280e-03],\n",
      "          [-1.3968e-03, -1.6492e-03, -1.4106e-03]],\n",
      "\n",
      "         [[-1.0010e-03, -4.0660e-04, -5.5592e-04],\n",
      "          [-3.1996e-04, -1.8985e-04, -7.5363e-04],\n",
      "          [-1.0683e-04,  1.2743e-04, -5.6474e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.2426e-03, -3.3011e-03, -3.2844e-03],\n",
      "          [-4.4981e-03, -3.4149e-03, -3.4183e-03],\n",
      "          [-4.5800e-03, -3.5865e-03, -3.2539e-03]],\n",
      "\n",
      "         [[-4.1233e-04, -2.0274e-04, -4.2856e-04],\n",
      "          [-3.0671e-05,  2.0260e-04,  2.7213e-04],\n",
      "          [ 2.9105e-04,  6.2743e-04,  2.8460e-04]],\n",
      "\n",
      "         [[-8.8132e-04, -4.4114e-04, -3.7458e-04],\n",
      "          [-9.0231e-04, -2.7770e-04, -2.5653e-04],\n",
      "          [-1.1965e-03, -2.9648e-04, -1.7524e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2536e-02, -1.2338e-02, -1.1330e-02],\n",
      "          [-1.2645e-02, -1.2714e-02, -1.1766e-02],\n",
      "          [-1.2208e-02, -1.2535e-02, -1.1328e-02]],\n",
      "\n",
      "         [[-1.2820e-03, -7.4145e-04, -8.9065e-04],\n",
      "          [-1.5330e-03, -9.2385e-04, -9.0806e-04],\n",
      "          [-2.3736e-03, -1.7960e-03, -1.5225e-03]],\n",
      "\n",
      "         [[-7.4074e-04, -6.0841e-04, -1.0870e-03],\n",
      "          [-7.8023e-04, -7.4839e-04, -1.0444e-03],\n",
      "          [-8.6841e-04, -1.0247e-03, -1.4432e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.2261e-04, -7.9438e-04, -7.2389e-04],\n",
      "          [-5.0473e-04, -6.8529e-04, -7.2760e-04],\n",
      "          [-6.0451e-04, -7.4918e-04, -6.8722e-04]],\n",
      "\n",
      "         [[-6.4652e-05, -1.9263e-05, -5.4839e-06],\n",
      "          [-1.1819e-04, -2.4064e-06,  4.1073e-06],\n",
      "          [-1.4164e-04, -9.1819e-05,  3.0382e-06]],\n",
      "\n",
      "         [[-1.9092e-04, -5.4455e-04, -1.5147e-04],\n",
      "          [-2.2512e-04, -4.8048e-04, -3.8288e-04],\n",
      "          [-2.5321e-04, -2.9871e-04, -3.8381e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7222e-03, -2.5286e-03, -3.2731e-03],\n",
      "          [-1.1612e-03, -1.8716e-03, -2.5812e-03],\n",
      "          [-9.4098e-04, -1.5181e-03, -2.0083e-03]],\n",
      "\n",
      "         [[-4.6319e-04, -7.9941e-04, -7.8054e-04],\n",
      "          [-4.5762e-04, -7.0095e-04, -8.4708e-04],\n",
      "          [-3.9621e-04, -5.1863e-04, -6.3527e-04]],\n",
      "\n",
      "         [[-3.6512e-05, -2.8523e-05,  4.6458e-06],\n",
      "          [-4.3981e-05, -2.8003e-05,  8.7700e-07],\n",
      "          [-7.8767e-05, -2.8167e-05, -2.5094e-05]]],\n",
      "\n",
      "\n",
      "        [[[-4.0566e-05, -2.9276e-05, -6.0189e-06],\n",
      "          [ 6.5242e-05,  5.5072e-05,  3.1899e-05],\n",
      "          [-2.6011e-05, -4.0932e-05, -9.9966e-06]],\n",
      "\n",
      "         [[ 2.2037e-04,  1.7115e-04, -1.0584e-04],\n",
      "          [ 3.3410e-04,  2.4464e-04, -6.2342e-05],\n",
      "          [-1.3715e-04, -6.4984e-05, -2.5790e-04]],\n",
      "\n",
      "         [[ 7.3046e-05,  9.3688e-05,  4.6138e-06],\n",
      "          [-4.3187e-05,  8.3579e-05,  3.8506e-06],\n",
      "          [-1.9283e-04, -7.9230e-05, -1.0974e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9156e-04, -1.2536e-04, -1.5405e-05],\n",
      "          [-1.5080e-04, -9.9053e-05, -2.9739e-05],\n",
      "          [-9.6826e-05, -9.9186e-05, -3.1926e-05]],\n",
      "\n",
      "         [[-2.1189e-05,  1.9213e-05, -4.4262e-06],\n",
      "          [-1.0725e-04, -4.0555e-05, -3.5356e-05],\n",
      "          [-7.3782e-05, -3.5687e-05, -8.7312e-06]],\n",
      "\n",
      "         [[-2.1496e-05, -3.1439e-05, -3.7237e-05],\n",
      "          [ 1.4342e-05, -2.2176e-05, -4.5268e-05],\n",
      "          [-3.6527e-07, -5.5827e-06, -2.7890e-05]]]]), 'exp_avg_sq': tensor([[[[1.6842e-04, 1.8729e-04, 1.6387e-04],\n",
      "          [1.7929e-04, 1.8142e-04, 1.6414e-04],\n",
      "          [1.8902e-04, 1.8011e-04, 1.5516e-04]],\n",
      "\n",
      "         [[1.0500e-05, 1.6354e-06, 4.0227e-06],\n",
      "          [1.4654e-05, 2.0581e-06, 1.8745e-06],\n",
      "          [1.3864e-05, 7.4657e-06, 1.0927e-05]],\n",
      "\n",
      "         [[2.4338e-05, 1.7217e-05, 8.6532e-06],\n",
      "          [2.6180e-05, 2.3272e-05, 1.5293e-05],\n",
      "          [2.1695e-05, 1.5906e-05, 1.6325e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[7.7315e-04, 8.6401e-04, 8.5635e-04],\n",
      "          [7.8344e-04, 8.7258e-04, 8.9929e-04],\n",
      "          [7.8933e-04, 8.4438e-04, 8.1698e-04]],\n",
      "\n",
      "         [[3.6969e-05, 3.2987e-05, 2.2927e-05],\n",
      "          [3.4887e-05, 3.7993e-05, 3.6544e-05],\n",
      "          [3.6468e-05, 3.1440e-05, 3.5951e-05]],\n",
      "\n",
      "         [[2.8555e-05, 3.0262e-05, 3.3552e-05],\n",
      "          [3.0689e-05, 2.8106e-05, 3.1628e-05],\n",
      "          [3.4765e-05, 2.9473e-05, 3.0317e-05]]],\n",
      "\n",
      "\n",
      "        [[[1.0058e-03, 9.7764e-04, 9.6284e-04],\n",
      "          [9.8123e-04, 9.8219e-04, 9.8796e-04],\n",
      "          [9.6141e-04, 1.0082e-03, 1.0241e-03]],\n",
      "\n",
      "         [[1.8118e-03, 1.8632e-03, 2.1591e-03],\n",
      "          [1.9158e-03, 2.0699e-03, 2.2019e-03],\n",
      "          [2.3310e-03, 2.5329e-03, 2.5666e-03]],\n",
      "\n",
      "         [[6.5263e-05, 7.5486e-05, 7.9448e-05],\n",
      "          [1.1485e-04, 1.1022e-04, 1.1933e-04],\n",
      "          [1.3800e-04, 1.6671e-04, 1.7060e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.6332e-04, 2.0699e-04, 1.5303e-04],\n",
      "          [1.7694e-04, 1.7669e-04, 1.3678e-04],\n",
      "          [1.3605e-04, 1.3810e-04, 1.2013e-04]],\n",
      "\n",
      "         [[4.1360e-04, 4.8308e-04, 4.6272e-04],\n",
      "          [5.1448e-04, 5.1111e-04, 5.2640e-04],\n",
      "          [4.7956e-04, 5.3245e-04, 5.5317e-04]],\n",
      "\n",
      "         [[2.7081e-04, 3.0232e-04, 3.2565e-04],\n",
      "          [3.0263e-04, 3.2344e-04, 3.2466e-04],\n",
      "          [2.7930e-04, 2.9863e-04, 3.1319e-04]]],\n",
      "\n",
      "\n",
      "        [[[5.5764e-04, 5.0637e-04, 4.2532e-04],\n",
      "          [5.3027e-04, 4.6271e-04, 3.9972e-04],\n",
      "          [4.8179e-04, 4.5339e-04, 4.0560e-04]],\n",
      "\n",
      "         [[3.4848e-05, 7.0975e-05, 1.2366e-04],\n",
      "          [6.9997e-06, 1.3201e-05, 4.2154e-05],\n",
      "          [1.2980e-05, 1.9172e-05, 3.6742e-05]],\n",
      "\n",
      "         [[6.0303e-06, 4.4743e-06, 1.2043e-05],\n",
      "          [7.7225e-06, 2.6287e-06, 4.0705e-06],\n",
      "          [1.3094e-05, 7.9309e-06, 6.7638e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.5713e-03, 2.4913e-03, 2.2417e-03],\n",
      "          [2.6140e-03, 2.6495e-03, 2.3119e-03],\n",
      "          [2.2754e-03, 2.2674e-03, 2.0718e-03]],\n",
      "\n",
      "         [[6.5827e-05, 4.7650e-05, 5.2492e-05],\n",
      "          [8.5739e-05, 7.6110e-05, 6.6564e-05],\n",
      "          [8.2596e-05, 9.4568e-05, 7.9223e-05]],\n",
      "\n",
      "         [[7.6392e-05, 7.1055e-05, 6.6350e-05],\n",
      "          [6.9842e-05, 7.2433e-05, 7.4836e-05],\n",
      "          [6.3532e-05, 7.5626e-05, 8.2589e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.9070e-03, 1.8056e-03, 1.7919e-03],\n",
      "          [2.1063e-03, 1.8486e-03, 1.8053e-03],\n",
      "          [1.9092e-03, 1.7955e-03, 1.8378e-03]],\n",
      "\n",
      "         [[7.7354e-03, 7.6122e-03, 7.4942e-03],\n",
      "          [7.4635e-03, 7.0633e-03, 6.9127e-03],\n",
      "          [6.8977e-03, 7.1232e-03, 7.3939e-03]],\n",
      "\n",
      "         [[1.6312e-03, 1.6607e-03, 1.5735e-03],\n",
      "          [1.5924e-03, 1.5253e-03, 1.5592e-03],\n",
      "          [1.6584e-03, 1.5078e-03, 1.6020e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5.5450e-03, 5.5116e-03, 4.9004e-03],\n",
      "          [5.7618e-03, 5.8017e-03, 5.1509e-03],\n",
      "          [5.7277e-03, 5.5602e-03, 5.0637e-03]],\n",
      "\n",
      "         [[9.3180e-04, 8.5839e-04, 8.2076e-04],\n",
      "          [8.3163e-04, 7.6023e-04, 8.3822e-04],\n",
      "          [1.0209e-03, 9.7755e-04, 9.8301e-04]],\n",
      "\n",
      "         [[4.5455e-04, 4.3826e-04, 4.9942e-04],\n",
      "          [4.6247e-04, 4.3536e-04, 5.0169e-04],\n",
      "          [4.3677e-04, 4.9364e-04, 5.3524e-04]]],\n",
      "\n",
      "\n",
      "        [[[2.1567e-04, 3.1813e-04, 2.8397e-04],\n",
      "          [2.2904e-04, 3.0799e-04, 2.5125e-04],\n",
      "          [2.2667e-04, 2.7974e-04, 2.2999e-04]],\n",
      "\n",
      "         [[2.0700e-05, 1.0984e-05, 5.1416e-06],\n",
      "          [2.5567e-05, 7.9328e-06, 5.2095e-07],\n",
      "          [1.3763e-05, 3.6501e-06, 1.5275e-06]],\n",
      "\n",
      "         [[8.4544e-06, 1.1897e-05, 2.1609e-06],\n",
      "          [7.5358e-06, 1.1946e-05, 1.8820e-06],\n",
      "          [7.3921e-06, 8.0471e-06, 1.7941e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.3687e-03, 1.7413e-03, 1.9753e-03],\n",
      "          [1.3334e-03, 1.7215e-03, 1.9843e-03],\n",
      "          [1.3875e-03, 1.7622e-03, 1.9068e-03]],\n",
      "\n",
      "         [[2.8866e-05, 3.3580e-05, 2.0672e-05],\n",
      "          [2.2874e-05, 2.5287e-05, 1.9268e-05],\n",
      "          [2.8189e-05, 2.5047e-05, 2.1099e-05]],\n",
      "\n",
      "         [[2.8083e-05, 3.1709e-05, 3.3983e-05],\n",
      "          [2.6851e-05, 2.7223e-05, 2.5240e-05],\n",
      "          [2.7007e-05, 2.4644e-05, 2.5343e-05]]],\n",
      "\n",
      "\n",
      "        [[[1.0219e-03, 8.5024e-04, 9.1594e-04],\n",
      "          [1.0346e-03, 1.0417e-03, 1.0996e-03],\n",
      "          [9.8658e-04, 1.1005e-03, 1.0241e-03]],\n",
      "\n",
      "         [[7.6922e-03, 8.1559e-03, 8.7669e-03],\n",
      "          [7.6297e-03, 8.5852e-03, 8.9671e-03],\n",
      "          [8.0939e-03, 7.5405e-03, 7.3502e-03]],\n",
      "\n",
      "         [[1.3685e-03, 1.3623e-03, 1.6304e-03],\n",
      "          [1.5711e-03, 1.3832e-03, 1.5703e-03],\n",
      "          [1.6093e-03, 1.4755e-03, 1.3283e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[7.2493e-04, 6.9897e-04, 6.1846e-04],\n",
      "          [6.2140e-04, 6.3092e-04, 6.4131e-04],\n",
      "          [5.2009e-04, 5.8409e-04, 6.7692e-04]],\n",
      "\n",
      "         [[6.6443e-04, 6.2299e-04, 6.9552e-04],\n",
      "          [8.5355e-04, 7.8808e-04, 6.8034e-04],\n",
      "          [7.6117e-04, 7.7118e-04, 6.5794e-04]],\n",
      "\n",
      "         [[3.1452e-04, 3.1930e-04, 3.2904e-04],\n",
      "          [3.4638e-04, 3.9007e-04, 3.7166e-04],\n",
      "          [3.5115e-04, 3.7808e-04, 3.3248e-04]]]])}, 3: {'step': 170, 'exp_avg': tensor([-7.8069e-04,  2.6297e-03, -7.3291e-03,  2.6777e-02, -1.0844e-03,\n",
      "        -2.8347e-03, -9.6357e-05, -1.1472e-03, -3.5199e-03, -7.9999e-03,\n",
      "        -2.8210e-03, -3.0889e-02, -1.3358e-02, -1.2698e-02, -1.2830e-02,\n",
      "        -1.2880e-02, -1.4934e-02, -1.5672e-02, -3.2488e-02, -2.7654e-05,\n",
      "         4.4346e-02, -1.0563e-02, -3.6374e-03, -1.9081e-04]), 'exp_avg_sq': tensor([0.0016, 0.0029, 0.0028, 0.0094, 0.0020, 0.0225, 0.0115, 0.0055, 0.0198,\n",
      "        0.0126, 0.0057, 0.0013, 0.0055, 0.0130, 0.0048, 0.0088, 0.0053, 0.0249,\n",
      "        0.0989, 0.0001, 0.0131, 0.0163, 0.0016, 0.0086])}, 4: {'step': 170, 'exp_avg': tensor([[ 3.0338e-04,  1.4213e-06,  1.1008e-04,  ...,  4.3620e-05,\n",
      "         -2.2626e-04, -2.4326e-04],\n",
      "        [-3.0338e-04, -1.4213e-06, -1.1008e-04,  ..., -4.3620e-05,\n",
      "          2.2626e-04,  2.4326e-04]]), 'exp_avg_sq': tensor([[1.0510e-05, 2.5726e-06, 3.2417e-06,  ..., 5.5660e-05, 9.2625e-05,\n",
      "         1.3355e-04],\n",
      "        [1.0510e-05, 2.5726e-06, 3.2417e-06,  ..., 5.5660e-05, 9.2625e-05,\n",
      "         1.3355e-04]])}, 5: {'step': 170, 'exp_avg': tensor([ 0.0018, -0.0018]), 'exp_avg_sq': tensor([0.0031, 0.0031])}}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5]}]\n"
     ]
    }
   ],
   "source": [
    "# 모델의 state_dict 출력\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# 옵티마이저의 state_dict 출력\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8a36b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced3b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
