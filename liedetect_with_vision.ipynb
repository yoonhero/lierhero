{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.data.transforms import get_image_files\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(fname, size=224):\n",
    "    img = PIL.Image.open(fname).convert('RGB')\n",
    "    img = img.resize((size, size))\n",
    "    t = torch.Tensor(np.array(img))\n",
    "    return t.permute(2,0,1).float()/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transform \n",
    "class ImageTransform():\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,files, labels):\n",
    "        self.files, self.labels = files, labels\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        file = self.files[i]\n",
    "        \n",
    "        img = open_image(file)\n",
    "        label = self.labels[i]\n",
    "\n",
    "        return (img, label)\n",
    "\n",
    "    def __len__(self): return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file_list(path):\n",
    "    train_img_list = list()\n",
    "\n",
    "    with os.scandir(path) as files:\n",
    "        for file in files:\n",
    "            if file.name.endswith('.jpg'):\n",
    "              # adds only the image files to the flowers list\n",
    "                train_img_list.append(f\"{path}/{file.name}\")\n",
    "    \n",
    "    return train_img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train dataloader list\n",
    "\n",
    "lie_img_path = r\"./dataset/lie\"\n",
    "not_lie_img_path = r\"./dataset/not_lie\"\n",
    "\n",
    "lie_files = make_file_list(lie_img_path)\n",
    "not_lie_files = make_file_list(not_lie_img_path)\n",
    "\n",
    "files = lie_files + not_lie_files\n",
    "labels = [\"lie\" ]*len(lie_files)+[\"not_lie\"]*len(not_lie_files)\n",
    "\n",
    "not_lie_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.random.permutation(range(len(files)))\n",
    "cut = int(0.8 * len(files))\n",
    "train_files = files[idxs[:cut]]\n",
    "valid_files = files[idxs[cut:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageDataset(train_files)\n",
    "valid_ds = ImageDataset(valid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "dls = DataLoaders.from_dsets(train_ds, valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=error_rate, pretrained=True)\n",
    "learn.fine_tune(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(\"file_name\")\n",
    "\n",
    "label, _, probs = learn.predict(img)\n",
    "\n",
    "\n",
    "print(f\"You are {label}\")\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/Sebastian-Schuchmann/ChurrorsSamosaClassifier/blob/main/Train_a_Food_Model.ipynb#scrollTo=KddD9EmLdon0\n",
    "\n",
    "#let's grab the first pkl file we can find\n",
    "modelPath = get_files(foodPath, '.pkl')[0]\n",
    "modelPath\n",
    "\n",
    "learn_inf = load_learner(modelPath)\n",
    "learn_inf.predict(mpimg.imread(get_image_files(foodPath)[0])) #raw prediction\n",
    "\n",
    "learn_inf.dls.vocab #Get the labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9585e0e58f3ada4c387d89b399b9d9bb88b52954ed4e2235f58d5a052e970ed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
